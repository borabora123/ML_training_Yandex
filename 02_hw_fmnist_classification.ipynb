{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDsVMGiVgSq2"
      },
      "source": [
        "## Классификация FashionMNIST\n",
        "\n",
        "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/s/girafe_ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3isBRG6PgSq6"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.datasets import FashionMNIST\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_vOHg8Ucey2"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "\n",
        "def parse_pytorch_model(model_str):\n",
        "    def parse_layer(layer_str):\n",
        "        layer_info = {}\n",
        "        layer_name, params = layer_str.split(\"(\", 1)\n",
        "        params = params.rstrip(\")\")\n",
        "        layer_info[\"type\"] = layer_name.strip()\n",
        "        param_dict = {}\n",
        "        for param in params.split(\", \"):\n",
        "            if \"=\" in param:\n",
        "                key, value = param.split(\"=\")\n",
        "                param_dict[key.strip()] = eval(value.strip())\n",
        "            else:\n",
        "                param_dict[param.strip()] = None\n",
        "        layer_info[\"parameters\"] = param_dict\n",
        "        return layer_info\n",
        "\n",
        "    model_dict = {}\n",
        "    lines = model_str.splitlines()\n",
        "    model_name = lines[0].strip(\"()\")\n",
        "    model_dict[\"model_name\"] = model_name\n",
        "    model_dict[\"layers\"] = []\n",
        "\n",
        "    layer_regex = re.compile(r\"\\((\\d+)\\): (.+)\")\n",
        "    for line in lines[1:]:\n",
        "        line = line.strip()\n",
        "        match = layer_regex.match(line)\n",
        "        if match:\n",
        "            index, layer = match.groups()\n",
        "            model_dict[\"layers\"].append({\"index\": int(index), \"layer\": parse_layer(layer)})\n",
        "    return model_dict\n",
        "\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qhQLloqcey2"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "def get_predictions(model, eval_data, step=10):\n",
        "\n",
        "    predicted_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, len(eval_data), step):\n",
        "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
        "    return predicted_labels\n",
        "\n",
        "\n",
        "def get_accuracy(model, data_loader):\n",
        "    predicted_labels = []\n",
        "    real_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            y_predicted = model(batch[0].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "            real_labels.append(batch[1])\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    real_labels = torch.cat(real_labels)\n",
        "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
        "    return accuracy_score\n",
        "\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "six9AcCJcey2"
      },
      "source": [
        "Загрузите файл `hw_overfitting_data_dict.npy` (ссылка есть на странице с заданием), он понадобится для генерации посылок. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fN9ZRBscey3",
        "outputId": "02552f49-a147-4ec1-abe5-9087a4cecfbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-09 14:52:57--  https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving github.com (github.com)... 140.82.116.4\n",
            "Connecting to github.com (github.com)|140.82.116.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict [following]\n",
            "--2025-04-09 14:52:57--  https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6272446 (6.0M) [application/octet-stream]\n",
            "Saving to: ‘hw_overfitting_data_dict.npy’\n",
            "\n",
            "hw_overfitting_data 100%[===================>]   5.98M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-04-09 14:52:57 (110 MB/s) - ‘hw_overfitting_data_dict.npy’ saved [6272446/6272446]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict -O hw_overfitting_data_dict.npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZyCYZHqcey3"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeA6Q5-CgSq7"
      },
      "source": [
        "Вернемся к задаче распознавания простых изображений, рассмотренной ранее. Но теперь будем работать с набором данных [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). В данном задании воспользуемся всем датасетом целиком.\n",
        "\n",
        "__Ваша первая задача: реализовать весь пайплан обучения модели и добиться качества $\\geq 88.5\\%$ на тестовой выборке.__\n",
        "\n",
        "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбукам с предыдущих занятий."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwbBP3HAcey3"
      },
      "outputs": [],
      "source": [
        "CUDA_DEVICE_ID = 0  # change if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPG1KbQAgl8b"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "device = (\n",
        "    torch.device(f\"cuda:{CUDA_DEVICE_ID}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        ")\n",
        "device = 'cpu'\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "id": "aYcL28OsgSq8",
        "outputId": "a1804d98-1af6-4a83-86e7-d45b7a358432"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 13.2MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 208kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.84MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 10.8MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Image label: 7')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "train_fmnist_data = FashionMNIST(\n",
        "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "test_fmnist_data = FashionMNIST(\n",
        "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
        ")\n",
        "\n",
        "random_batch = next(iter(train_data_loader))\n",
        "_image, _label = random_batch[0][0], random_batch[1][0]\n",
        "plt.figure()\n",
        "plt.imshow(_image.reshape(28, 28))\n",
        "plt.title(f\"Image label: {_label}\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6jWRv1rgSq8"
      },
      "source": [
        "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 88.5% accuracy.\n",
        "\n",
        "__Внимание, ваша модель должна быть представлена именно переменной `model_task_1`. На вход ей должен приходить тензор размерностью (1, 28, 28).__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNetImproved(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(LeNetImproved, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=13, padding=6)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=7, padding=3)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.fc1 = nn.Linear(64*7*7, 1024)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(1024, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "def initialize_parameters(model, method='xavier', gain=1.0):\n",
        "    \"\"\"Custom parameter initialization for PyTorch model.\"\"\"\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'weight' in name and 'bn' not in name:\n",
        "            if method == 'xavier':\n",
        "                nn.init.xavier_normal_(param.data, gain=gain)\n",
        "            elif method == 'kaiming':\n",
        "                nn.init.kaiming_normal_(param.data, mode='fan_out', nonlinearity='relu')\n",
        "            elif method == 'orthogonal':\n",
        "                nn.init.orthogonal_(param.data, gain=gain)\n",
        "        elif 'bias' in name:\n",
        "            nn.init.zeros_(param.data)"
      ],
      "metadata": {
        "id": "D1v1zGhzcwBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcyEFX-RgSq8"
      },
      "outputs": [],
      "source": [
        "# Creating model instance\n",
        "model_task_1 = LeNetImproved()\n",
        "initialize_parameters(model_task_1)\n",
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAoLV4dkoy5M"
      },
      "source": [
        "Не забудьте перенести модель на выбранный `device`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xas9SIXDoxvZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c59efe7-1e44-499e-cfe4-54b15ac9ad86"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LeNetImproved(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(13, 13), stride=(1, 1), padding=(6, 6))\n",
              "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
              "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc1): Linear(in_features=3136, out_features=1024, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc2): Linear(in_features=1024, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "model_task_1.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pLRWysggSq9"
      },
      "source": [
        "Локальные тесты для проверки вашей модели доступны ниже:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qMQzo1ggSq9",
        "outputId": "6140c4c6-cdfd-4cd9-ad25-5858e9427642"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything seems fine!\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
        "\n",
        "try:\n",
        "    x = random_batch[0].to(device)\n",
        "    y = random_batch[1].to(device)\n",
        "\n",
        "    # compute outputs given inputs, both are variables\n",
        "    y_predicted = model_task_1(x)\n",
        "except Exception as e:\n",
        "    print(\"Something is wrong with the model\")\n",
        "    raise e\n",
        "\n",
        "\n",
        "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
        "\n",
        "print(\"Everything seems fine!\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suRmIPwIgSq9"
      },
      "source": [
        "Настройте параметры модели на обучающей выборке. Также рекомендуем поработать с `learning rate`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJnU14bdnZa_"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model_task_1.parameters(), lr=0.0005, weight_decay=0.067)\n",
        "\n",
        "loaders = {\"train\": train_data_loader, \"valid\": test_data_loader}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, criterion, optimizer):\n",
        "  max_epochs = 10\n",
        "  accuracy = {\"train\": [], \"valid\": []}\n",
        "  for epoch in range(max_epochs):\n",
        "      for k, dataloader in loaders.items():\n",
        "          epoch_correct = 0\n",
        "          epoch_all = 0\n",
        "          for x_batch, y_batch in tqdm(dataloader):\n",
        "              if k == \"train\":\n",
        "                  model.train()\n",
        "                  optimizer.zero_grad()\n",
        "                  outp = model(x_batch.to(device))\n",
        "                  loss = criterion(outp, y_batch.to(device))\n",
        "                  loss.backward()\n",
        "                  optimizer.step()\n",
        "              else:\n",
        "                  model.eval()\n",
        "                  with torch.no_grad():\n",
        "                      outp = model(x_batch.to(device))\n",
        "              preds = outp.argmax(-1).to('cpu')\n",
        "              correct =  torch.mean((preds==y_batch).float())\n",
        "              all = y_batch.shape[0]\n",
        "              epoch_correct += torch.sum((preds==y_batch).float())\n",
        "              epoch_all += all\n",
        "          if k == \"train\":\n",
        "              print(f\"Epoch: {epoch+1}\")\n",
        "          print(f\"Loader: {k}. Accuracy: {epoch_correct/epoch_all}\")\n",
        "          accuracy[k].append(epoch_correct/epoch_all)\n",
        "  return model, accuracy['valid']"
      ],
      "metadata": {
        "id": "MrsojxyNdd_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_task_1, lenet_accuracy = train(model_task_1, criterion, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "2QRixodSdh50",
        "outputId": "3615cfef-4d73-4982-979a-8e5533c9a8c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1875/1875 [05:11<00:00,  6.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "Loader: train. Accuracy: 0.9370999932289124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:12<00:00, 24.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loader: valid. Accuracy: 0.9067000150680542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 75/1875 [00:12<05:03,  5.92it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-14d4384b9fd6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_task_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlenet_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_task_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-43-dd2c212cea63>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer)\u001b[0m\n\u001b[1;32m     13\u001b[0m                   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                   \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m                             )\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    241\u001b[0m             )\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             adamw(\n\u001b[0m\u001b[1;32m    244\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adamw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    876\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zce7gt1gSq-"
      },
      "source": [
        "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usswrWYOgSq-"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xua3TVZHgSq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e04514f2-a899-40d3-c726-656b3ad6b791"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.95702\n"
          ]
        }
      ],
      "source": [
        "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9KEKXBxgSq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeca0613-559e-4f17-f2d0-1f6e69531970"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.9178\n"
          ]
        }
      ],
      "source": [
        "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oyhmMobgSq_"
      },
      "source": [
        "Проверка, что необходимые пороги пройдены:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAIrURCEgSq_"
      },
      "outputs": [],
      "source": [
        "assert test_acc_task_1 >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
        "assert (\n",
        "    train_acc_task_1 >= 0.905\n",
        "), \"Train accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru71fIzPcey5"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_1`, а файл `hw_fmnist_data_dict.npy` находится в той же директории, что и ноутбук (он доступен в репозитории)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parse_pytorch_model(str(model_task_1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlTkU9r8pX0d",
        "outputId": "c9ce6c75-0d46-4e17-f8a4-0bf537734a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(conv1): Conv2d(1, 32, kernel_size=(13, 13), stride=(1, 1), padding=(6, 6))\n",
            "None\n",
            "(bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "None\n",
            "(conv2): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
            "None\n",
            "(bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "None\n",
            "(fc1): Linear(in_features=3136, out_features=1024, bias=True)\n",
            "None\n",
            "(dropout): Dropout(p=0.5, inplace=False)\n",
            "None\n",
            "(fc2): Linear(in_features=1024, out_features=10, bias=True)\n",
            "None\n",
            ")\n",
            "None\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_name': 'LeNetImproved', 'layers': []}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4MS3zjjcey5",
        "outputId": "02fc28a9-ca1b-4b06-d0a3-c3a4c7e6f905"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict_fmnist_task_1.json`\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_fmnist_data_dict.npy\"\n",
        "), \"Please, download `hw_fmnist_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(\"hw_fmnist_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "submission_dict = {\n",
        "    \"train_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "    ),\n",
        "    \"test_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "    ),\n",
        "    \"model_task_1\": parse_pytorch_model(str(model_task_1)),\n",
        "}\n",
        "\n",
        "with open(\"submission_dict_fmnist_task_1.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `submission_dict_fmnist_task_1.json`\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPt3JvB1cey5"
      },
      "source": [
        "### Сдача задания\n",
        "Сдайте сгенерированный файл в соответствующую задачу в соревновании, а именно:\n",
        "    \n",
        "* `submission_dict_fmnist_task_1.json` в задачу Separation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtWnYAN_gSrA"
      },
      "source": [
        "На этом задание завершено. Поздравляем!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "facelv_1.13+cu117",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "21499ab2a6726e29f7050b76af0e9680227e613293d630ba279de7ebdfad9cae"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}